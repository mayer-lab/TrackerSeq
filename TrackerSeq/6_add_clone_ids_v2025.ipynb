{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01fd41-57d8-41b1-bc9d-7febf9245cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.sparse import csr_matrix, coo_matrix, csc_matrix\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f91b65-4c36-411e-a6b7-282ac6bdc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scverse libraries\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pertpy as pt\n",
    "import matplotlib.pyplot as plt\n",
    "# Data retrieval\n",
    "import pooch\n",
    "import scanpy.external as sce\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953f63f-6eb3-4880-a050-400b02d68b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233c9ed-b144-4d95-b39b-1ed4ae2bbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sparse matrix(es) -- there may be multiple if experiment is split across single-cell preps\n",
    "sparse_path_1 = 'xyz.csv'\n",
    "if os.path.exists(sparse_path_1):\n",
    "    sparse_matrix_1 = pd.read_csv(sparse_path_1, sep=',', header = 'infer', index_col='cellbc')\n",
    "sparse_matrix_1.index = sparse_matrix_1.index + \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdadb81-572d-46f9-98f3-49346ea68ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c677333-757c-4b06-b598-e60a4675b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second sparse matrix if second single-cell kit is used\n",
    "sparse_path_2 = 'xyz.csv'\n",
    "if os.path.exists(sparse_path_2):\n",
    "    sparse_matrix_2 = pd.read_csv(sparse_path_2, sep=',', header = 'infer', index_col='cellbc')\n",
    "sparse_matrix_2.index = sparse_matrix_2.index + \"-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cfa95-db5b-4d09-96bb-83cb18402b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db58f27-6679-4b68-a10a-6159ea78d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In parallel, best to perform doublet detection on transcriptome dataset and port over list of\n",
    "# detected & removed doublets for upstream removal of their signals here, since doublets may drive \n",
    "# artificial clone collisions\n",
    "doublet_df = pd.read_csv('zyx.csv', index_col = 'cellbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58c384-05c9-443e-8f4e-1c8a1a45ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublet_df = doublet_df.rename(columns={'Unnamed: 0': \"doublet_cells\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0e54d-af41-4c65-a067-ce9f49df6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge each sparse matrix into a larger matrix using outer concatenation\n",
    "sparse_matrix_list = [sparse_matrix_1, sparse_matrix_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acbc9a-8251-4041-8828-2eab63c0c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = pd.concat(sparse_matrix_list, join = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50af65-2a34-43e0-81e1-ab4ed0f88200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain sparse matrix format by filling missing values with 0\n",
    "sparse_matrix = sparse_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d26b19-9404-47e6-9c64-2f20648e1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a9d49-49ae-4a9e-96c5-4862c812f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out doublet cells from the transcriptome and (for example) gRNA analysis - \n",
    "sparse_matrix = sparse_matrix[~sparse_matrix.index.isin(doublet_df.index)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bd5e0-1cfa-4da2-ba71-8d3a6644fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check removed shape post doublet removal\n",
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69be8cd-fac9-4415-b5b4-85d93b3fe4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lineage barcode columns now empty after doublet removal\n",
    "sparse_matrix = sparse_matrix.loc[:, sparse_matrix.sum() != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437bdf2-01b8-4b9e-bfe4-4cfadd9c0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again check mtx post doublet-only LBC removal\n",
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4cd8a-4090-4c0f-a731-ea18f5d0331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_lbc_sums= np.sum(sparse_matrix, axis = 0)\n",
    "sparse_cell_sums = np.sum(sparse_matrix, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0c699-4d27-47b8-8149-9b63ea6769ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot statistics of lineage barcodes per cell \n",
    "plt.hist(sparse_lbc_sums, bins = 10)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938eb66f-e12b-44b2-8876-4ca522704feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot statistics of cells per lineage barcode \n",
    "plt.hist(sparse_cell_sums, bins = 50)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79920f3-5ba6-4185-a053-e21e7ce19784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.sparse import csr_matrix, coo_matrix, csc_matrix\n",
    "\n",
    "mp.set_start_method(\"fork\", force=True)\n",
    "\n",
    "def convert_to_sparse_matrix(mtx):\n",
    "    \"\"\"Convert input matrix to a SciPy CSR sparse matrix while preserving structure.\"\"\"\n",
    "    if isinstance(mtx, (coo_matrix, csc_matrix)):\n",
    "        return mtx.tocsr()\n",
    "    elif not isinstance(mtx, csr_matrix):\n",
    "        return csr_matrix(mtx)\n",
    "    return mtx\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    return jaccard_score(np.isin(range(max(max(set1, default=0), max(set2, default=0)) + 1), set1).astype(int),\n",
    "                          np.isin(range(max(max(set1, default=0), max(set2, default=0)) + 1), set2).astype(int))\n",
    "\n",
    "def process_barcode(lbc_idx, mtx):\n",
    "    g_idx = mtx[:, lbc_idx].nonzero()[0]\n",
    "    g_idx_mtx = mtx[g_idx, :]\n",
    "    ncells_per_bc = g_idx_mtx.shape[0]\n",
    "    \n",
    "    edge_list = []\n",
    "    edge_attrs = []\n",
    "    weight_list = []\n",
    "    jac_list = []\n",
    "    \n",
    "    for j in range(ncells_per_bc - 1):\n",
    "        for k in range(j + 1, ncells_per_bc):\n",
    "            set1 = g_idx_mtx[j].nonzero()[1]\n",
    "            set2 = g_idx_mtx[k].nonzero()[1]\n",
    "            \n",
    "            bc_frac = 2 * len(set(set1).intersection(set2)) / (len(set1) + len(set2))\n",
    "            jac_frac = jaccard_similarity(set1, set2)\n",
    "            \n",
    "            edge_list.append((g_idx[j], g_idx[k]))\n",
    "            edge_attrs.append(lbc_idx)\n",
    "            weight_list.append(bc_frac)\n",
    "            jac_list.append(jac_frac)\n",
    "    \n",
    "    return edge_list, edge_attrs, weight_list, jac_list\n",
    "\n",
    "def build_graph_from_sparse_mtx_w_pattern_weights(mtx, n_cores, row_names=None, col_names=None):\n",
    "    mtx = convert_to_sparse_matrix(mtx)\n",
    "    \n",
    "    num_nodes = mtx.shape[0]\n",
    "    g = ig.Graph(directed=False)\n",
    "    g.add_vertices(num_nodes)\n",
    "    \n",
    "    if row_names is not None:\n",
    "        g.vs['cellID'] = row_names\n",
    "    else:\n",
    "        g.vs['cellID'] = list(range(num_nodes))\n",
    "    \n",
    "    valid_cols = np.where(mtx.sum(axis=0) > 1)[1]\n",
    "    clean_mtx = mtx[:, valid_cols]\n",
    "    lbc_vec = valid_cols\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        with mp.Pool(n_cores) as pool:\n",
    "            results = pool.starmap(process_barcode, [(lbc_idx, mtx) for lbc_idx in lbc_vec])\n",
    "    \n",
    "        edges, edge_attrs, weights, jaccards = [], [], [], []\n",
    "        for res in results:\n",
    "            edges.extend(res[0])\n",
    "            edge_attrs.extend(res[1])\n",
    "            weights.extend(res[2])\n",
    "            jaccards.extend(res[3])\n",
    "    \n",
    "        g.add_edges(edges)\n",
    "    \n",
    "        if col_names is not None:\n",
    "            g.es['lbc_idx'] = [col_names[idx] for idx in edge_attrs]\n",
    "        else:\n",
    "            g.es['lbc_idx'] = edge_attrs\n",
    "    \n",
    "        g.es['weight'] = weights\n",
    "        g.es['jaccard_metric'] = jaccards\n",
    "    \n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ddc41-c618-42fa-aced-53b1e70bce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = build_graph_from_sparse_mtx_w_pattern_weights(sparse_matrix, row_names = sparse_matrix.index, col_names = sparse_matrix.columns, n_cores = 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bcddd-52b6-4787-a497-376b93ca49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant edges in the network (since edge weights contain information on \n",
    "# overlap of barcode signature, we only need one edge with the computed jaccard weight)\n",
    "g = g.simplify(multiple=True, combine_edges=dict(weight=\"mean\", jaccard_metric = 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655bff6a-bcd5-4ba9-8ec9-9b82e111d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the distribution of similarity scores among cell pairs in the data\n",
    "plt.hist(g.es['jaccard_metric'], bins = 101)\n",
    "plt.xlim(0,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc5293-5ce5-479c-b262-7f6b82e717f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Function to apply threshold and extract clones (filtered components)\n",
    "def network_patterning(gr: GraphBase, threshold: float) -> pd.DataFrame:\n",
    "    if threshold == 1:\n",
    "        exclusion_edges = [e.index for e in gr.es if e['weight'] < threshold]\n",
    "    elif threshold < 1:\n",
    "        exclusion_edges = [e.index for e in gr.es if e['weight'] <= threshold]\n",
    "    else:\n",
    "        exclusion_edges = []\n",
    "\n",
    "    filtered_graph = gr.copy()\n",
    "    filtered_graph.delete_edges(exclusion_edges)\n",
    "    components = filtered_graph.components()\n",
    "\n",
    "    clone_data = {\n",
    "        'cloneID': [],\n",
    "        'cellbc': []\n",
    "    }\n",
    "    for idx, comp in enumerate(components):\n",
    "        for node_idx in comp:\n",
    "            clone_data['cloneID'].append(idx)\n",
    "            clone_data['cellbc'].append(filtered_graph.vs[node_idx]['cellID'])\n",
    "\n",
    "    return pd.DataFrame(clone_data).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f68ece-885f-4d8b-aff0-09c3b35d2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_threshold(args):\n",
    "    gr, threshold = args\n",
    "    clones = network_patterning(gr, threshold)\n",
    "    clones = clones.rename(columns={'cloneID': f'cloneID_{threshold}'})\n",
    "    return clones\n",
    "\n",
    "\n",
    "def iterate_clone_pattern_parallel(gr: GraphBase, test_thresholds: list, max_workers=None) -> pd.DataFrame:\n",
    "    all_clones = network_patterning(gr, 1)\n",
    "    all_clones = all_clones.rename(columns={'cloneID': 'cloneID_1'})\n",
    "\n",
    "    args_list = [(gr.copy(), threshold) for threshold in test_thresholds]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers or multiprocessing.cpu_count()) as executor:\n",
    "        results = list(tqdm(executor.map(_run_threshold, args_list), total=len(args_list), desc=\"Processing thresholds\"))\n",
    "\n",
    "    for clone_df in results:\n",
    "        all_clones = pd.merge(all_clones, clone_df, on='cellbc', how='outer')\n",
    "\n",
    "    return all_clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6be7c-544a-470f-b62c-7ea415033865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_clone_lists(iterative_clone_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    from numpy import percentile\n",
    "\n",
    "    clone_cols = iterative_clone_df.columns[1:]\n",
    "    summary_list = []\n",
    "\n",
    "    for col in tqdm(clone_cols, desc=\"Summarizing clone lists\"):\n",
    "        data = iterative_clone_df[col].dropna()\n",
    "        if data.empty:\n",
    "            summary_list.append({'run': col, **{k: 0 for k in [\n",
    "                'length', 'biggest_clone_size', 'number_single', 'number_multicells',\n",
    "                'avg_clone_size', 'top5_avg', 'top10_avg', 'top25_avg',\n",
    "                'median_clone_size', 'clone_size_variance',\n",
    "                'top5_variance', 'top10_variance', 'top25_variance']}})\n",
    "            continue\n",
    "\n",
    "        counts = data.value_counts().values\n",
    "        multicells = counts[counts > 1]\n",
    "\n",
    "        top5, top10, top25 = percentile(multicells, [95, 90, 75]) if len(multicells) > 0 else (0, 0, 0)\n",
    "\n",
    "        def stats_above_thresh(vals, thresh):\n",
    "            subset = vals[vals > thresh]\n",
    "            return subset.mean() if subset.size > 0 else 0, subset.var() if subset.size > 0 else 0\n",
    "\n",
    "        top5_avg, top5_var = stats_above_thresh(multicells, top5)\n",
    "        top10_avg, top10_var = stats_above_thresh(multicells, top10)\n",
    "        top25_avg, top25_var = stats_above_thresh(multicells, top25)\n",
    "\n",
    "        summary_list.append({\n",
    "            'run': col,\n",
    "            'length': len(np.unique(data)),\n",
    "            'biggest_clone_size': counts.max(),\n",
    "            'number_single': (counts == 1).sum(),\n",
    "            'number_multicells': (counts > 1).sum(),\n",
    "            'avg_clone_size': multicells.mean() if len(multicells) > 0 else 0,\n",
    "            'top5_avg': top5_avg,\n",
    "            'top10_avg': top10_avg,\n",
    "            'top25_avg': top25_avg,\n",
    "            'median_clone_size': np.median(multicells) if len(multicells) > 0 else 0,\n",
    "            'clone_size_variance': multicells.var() if len(multicells) > 0 else 0,\n",
    "            'top5_variance': top5_var,\n",
    "            'top10_variance': top10_var,\n",
    "            'top25_variance': top25_var,\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_list)\n",
    "    summary_df['threshold'] = summary_df['run'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a264d-b824-4d69-8919-57df20f2124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "test_thresholds = np.arange(0, 1.0, 0.001)\n",
    "iterative_clone_df = iterate_clone_pattern_parallel(g, test_thresholds, max_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f699f-295a-40db-8b2c-f363fea46c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summarize_clone_lists(iterative_clone_df)\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e47c9e-8f7b-41fc-b36d-45cd95f94eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_clone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683432d1-3b30-43ec-a903-7ed52c2125c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05638d31-23df-4f2d-a34e-cd05a567592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_long = summary_df.melt(id_vars = 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156045a-b908-4836-b05c-6970104a9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd754fb1-bc0a-410d-907e-b68a047c896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone size variance is one of the best heuristic indicators of noise vs. quality data \n",
    "# The higher quality of TrackerSeq library (by high diversity & even representation) AND\n",
    "# the better the single cell preparation (e.g. risk of doublets, minimization of RNA dropouts),\n",
    "# less noise will be observed and the threshold jaccard metric can be lowered using these heuristics\n",
    "\n",
    "# Lower quality datasets will have massive variances that drop off precipitously (like a knee), \n",
    "# while high quality datasets may not have such a knee but variance will be low even at the low \n",
    "# end of the jaccard scores -- use the initial distribution of pairwise scores as a sanity check \n",
    "# when interpreting these values! \n",
    "\n",
    "sns.relplot(\n",
    "    data=summary_df,\n",
    "    x=\"threshold\", y=\"clone_size_variance\",\n",
    "    kind=\"line\",\n",
    "    height=3, aspect=1.5, facet_kws=dict(sharex=False)\n",
    ")\n",
    "\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1))  # xmax=1 assumes your values are between 0 and 1\n",
    "#plt.ylim(0,10)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.title('Collapsed barcode representation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9c35d-0165-4d49-8226-971ec9ecdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=summary_df,\n",
    "    x=\"threshold\", y=\"biggest_clone_size\",\n",
    "    kind=\"line\",\n",
    "    height=3, aspect=1.5, facet_kws=dict(sharex=False)\n",
    ")\n",
    "\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1))  # xmax=1 assumes your values are between 0 and 1\n",
    "#plt.ylim(0,100)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.title('Collapsed barcode representation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2951a-29a6-4f56-9b6b-dd3a2d88c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=summary_df,\n",
    "    x=\"threshold\", y=\"top10_avg\",\n",
    "    kind=\"line\",\n",
    "    height=3, aspect=1.5, facet_kws=dict(sharex=False)\n",
    ")\n",
    "\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1))  # xmax=1 assumes your values are between 0 and 1\n",
    "#plt.ylim(0,100)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.title('Collapsed barcode representation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89710313-4ae6-433e-a659-7655ae1ee264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=summary_df,\n",
    "    x=\"threshold\", y=\"number_multicells\",\n",
    "    kind=\"line\",\n",
    "    height=3, aspect=1.5, facet_kws=dict(sharex=False)\n",
    ")\n",
    "\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1))  # xmax=1 assumes your values are between 0 and 1\n",
    "#plt.ylim(0,100)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.title('Collapsed barcode representation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7dfd13-a8c5-41b4-b11a-4b3159436ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=summary_df,\n",
    "    x=\"threshold\", y=\"avg_clone_size\",\n",
    "    kind=\"line\",\n",
    "    height=3, aspect=1.5, facet_kws=dict(sharex=False)\n",
    ")\n",
    "\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1))  # xmax=1 assumes your values are between 0 and 1\n",
    "#plt.ylim(0,100)\n",
    "#plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('Collapsed barcode representation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11c498-70a8-4f82-b734-d2a6fbcbf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a threshold for filtering network edges based on jaccard metric, \n",
    "# using heuristics above to minimize noise while preserving clonal information\n",
    "# Toptier = perfect barcode matches only\n",
    "toptier_clones = iterative_clone_df[['cellbc','cloneID_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db311811-c0fb-4f46-9979-14580596216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toptier_clones.to_csv('toptier_clones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf278d8b-c534-4387-b60c-27cfbb7c0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practice is to generate and test multiple cutoffs and examine effects on clonal \n",
    "# analysis e.g. counts of shared clones across annotated groups, # implausible clones, \n",
    "# z-score coupling and correlation analysis\n",
    "clones_zero_point_5 = iterative_clone_df[['cellbc','cloneID_0.5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23e4bf-fadf-412f-8e4f-a846f3d38c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "clones_zero_point_5.to_csv('clones_0.5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f87e24-9ee4-4322-b13f-3b5217845a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clones_zero_point_2 = iterative_clone_df[['cellbc','cloneID_0.2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8664185-c30c-4df2-9572-066af670d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clones_zero_point_2.to_csv('clones_0.2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42fc6f3-e5de-4f6a-b92e-9657a1f272f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
